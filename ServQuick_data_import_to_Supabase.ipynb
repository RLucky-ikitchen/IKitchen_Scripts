{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEk420TP9W_Y",
        "outputId": "718253bb-dd30-471e-b8bf-85b9371e363c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supabase\n",
            "  Downloading supabase-2.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Collecting gotrue<3.0.0,>=2.10.0 (from supabase)\n",
            "  Downloading gotrue-2.11.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: httpx<0.28,>=0.26 in /usr/local/lib/python3.10/dist-packages (from supabase) (0.27.2)\n",
            "Collecting postgrest<0.19,>=0.18 (from supabase)\n",
            "  Downloading postgrest-0.18.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting realtime<3.0.0,>=2.0.0 (from supabase)\n",
            "  Downloading realtime-2.0.6-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting storage3<0.10.0,>=0.9.0 (from supabase)\n",
            "  Downloading storage3-0.9.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting supafunc<0.8.0,>=0.7.0 (from supabase)\n",
            "  Downloading supafunc-0.7.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28,>=0.26->supabase) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28,>=0.26->supabase) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28,>=0.26->supabase) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28,>=0.26->supabase) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28,>=0.26->supabase) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28,>=0.26->supabase) (0.14.0)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<0.19,>=0.18->supabase)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: strenum<0.5.0,>=0.4.9 in /usr/local/lib/python3.10/dist-packages (from postgrest<0.19,>=0.18->supabase) (0.4.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.10.10 in /usr/local/lib/python3.10/dist-packages (from realtime<3.0.0,>=2.0.0->supabase) (3.11.2)\n",
            "Collecting websockets<14,>=11 (from realtime<3.0.0,>=2.0.0->supabase)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.10->realtime<3.0.0,>=2.0.0->supabase) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.10->realtime<3.0.0,>=2.0.0->supabase) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.10->realtime<3.0.0,>=2.0.0->supabase) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.10->realtime<3.0.0,>=2.0.0->supabase) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.10->realtime<3.0.0,>=2.0.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.10->realtime<3.0.0,>=2.0.0->supabase) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.10->realtime<3.0.0,>=2.0.0->supabase) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.10.10->realtime<3.0.0,>=2.0.0->supabase) (4.0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation<3.0.0,>=2.1.0->postgrest<0.19,>=0.18->supabase) (24.2)\n",
            "Collecting h2<5,>=3 (from httpx[http2]<0.28,>=0.26->gotrue<3.0.0,>=2.10.0->supabase)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28,>=0.26->supabase) (1.2.2)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<0.28,>=0.26->gotrue<3.0.0,>=2.10.0->supabase)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<0.28,>=0.26->gotrue<3.0.0,>=2.10.0->supabase)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading supabase-2.10.0-py3-none-any.whl (16 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading gotrue-2.11.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading postgrest-0.18.0-py3-none-any.whl (21 kB)\n",
            "Downloading realtime-2.0.6-py3-none-any.whl (20 kB)\n",
            "Downloading storage3-0.9.0-py3-none-any.whl (16 kB)\n",
            "Downloading supafunc-0.7.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: websockets, python-dotenv, hyperframe, hpack, deprecation, h2, supafunc, storage3, realtime, postgrest, gotrue, supabase\n",
            "Successfully installed deprecation-2.1.0 gotrue-2.11.0 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 postgrest-0.18.0 python-dotenv-1.0.1 realtime-2.0.6 storage3-0.9.0 supabase-2.10.0 supafunc-0.7.0 websockets-13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install supabase pandas python-dotenv pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv supabase.env .env\n"
      ],
      "metadata": {
        "id": "31BbbTCIrZZ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ServQuick data"
      ],
      "metadata": {
        "id": "NrIbuRsGEi3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import uuid\n",
        "from supabase import create_client, Client\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "\n",
        "if not SUPABASE_URL or not SUPABASE_KEY:\n",
        "    raise ValueError(\"Supabase credentials are missing. Check your .env file.\")\n",
        "\n",
        "# Initialize Supabase client\n",
        "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "# Function to insert unique customers\n",
        "def insert_customer(customer):\n",
        "    existing_customer = supabase.table(\"Customers\").select(\"*\").eq(\"phone_number\", customer[\"phone_number\"]).execute()\n",
        "    if not existing_customer.data:\n",
        "        customer_id = str(uuid.uuid4())  # Generate a unique ID for the customer\n",
        "        customer[\"customer_id\"] = customer_id\n",
        "\n",
        "        # Ensure all values in the customer dictionary are valid JSON types\n",
        "        for key, value in customer.items():\n",
        "            if pd.isnull(value):  # Check for NaN values\n",
        "                customer[key] = None  # Replace NaN with None\n",
        "            elif isinstance(value, float) and (pd.isna(value) or value == float('inf') or value == float('-inf')):\n",
        "                customer[key] = None  # Replace infinite or NaN floats with None\n",
        "            # Add other checks and conversions for potential invalid values\n",
        "\n",
        "        supabase.table(\"Customers\").insert(customer).execute()\n",
        "        return customer_id\n",
        "    return existing_customer.data[0][\"customer_id\"]\n",
        "\n",
        "# Function to insert orders\n",
        "def insert_order(order):\n",
        "    supabase.table(\"Orders\").insert(order).execute()\n",
        "\n",
        "# Read and process the Excel file\n",
        "def process_excel(file_path):\n",
        "    # Read the Excel file\n",
        "    data = pd.read_excel(file_path)\n",
        "\n",
        "    column_map = {\n",
        "        \"Customer name\": \"Customer name\",\n",
        "        \"Customer mobile\": \"Customer mobile\",\n",
        "        \"Customer email\": \"Customer email\",\n",
        "        \"Customer address\": \"Customer address\",\n",
        "        \"Sale date\": \"Sale date\",\n",
        "        \"Receipt no\": \"Receipt no\",\n",
        "        \"Ordertype name\": \"Ordertype name\",\n",
        "        \"Item name\": \"Item name\",\n",
        "        \"Variant name\": \"Variant name\",\n",
        "        \"Selling price\": \"Selling price\",\n",
        "        \"Item quantity\": \"Item quantity\",\n",
        "        \"Item amount\": \"Item amount\",\n",
        "    }\n",
        "\n",
        "    # Ensure the necessary columns exist\n",
        "    required_columns = column_map.keys()\n",
        "    for col in required_columns:\n",
        "        if col not in data.columns:\n",
        "            raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "    # Convert numeric columns to proper types\n",
        "    data[\"Item quantity\"] = pd.to_numeric(data[\"Item quantity\"], errors=\"coerce\")\n",
        "    data[\"Item amount\"] = pd.to_numeric(data[\"Item amount\"], errors=\"coerce\")\n",
        "\n",
        "    # Group items by receipt ID\n",
        "    grouped = data.groupby(\"Receipt no\").apply(lambda group: {\n",
        "        \"order_items\": group.apply(lambda row: {\n",
        "            \"item_name\": row[\"Item name\"],\n",
        "            \"quantity\": row[\"Item quantity\"],\n",
        "            \"amount\": row[\"Item amount\"],\n",
        "        }, axis=1).tolist(),\n",
        "        \"order_items_text\": \"; \".join(\n",
        "            f'{row[\"Item name\"]} (x{row[\"Item quantity\"]})' for _, row in group.iterrows()\n",
        "        ),\n",
        "    }).reset_index(name=\"grouped_data\")\n",
        "\n",
        "    # Extract grouped data into a DataFrame\n",
        "    grouped_data = pd.json_normalize(grouped[\"grouped_data\"])\n",
        "    grouped = pd.concat([grouped, grouped_data], axis=1)\n",
        "\n",
        "    # Merge grouped data back with the original dataset\n",
        "    final_data = pd.merge(data.drop_duplicates(\"Receipt no\"), grouped, on=\"Receipt no\", how=\"left\")\n",
        "\n",
        "    # Process customers and orders\n",
        "    for _, row in final_data.iterrows():\n",
        "        # Extract customer details\n",
        "        customer = {\n",
        "            \"name\": row[column_map[\"Customer name\"]],\n",
        "            \"phone_number\": row[column_map[\"Customer mobile\"]],\n",
        "            \"email\": row[column_map[\"Customer email\"]],\n",
        "            \"address\": row[column_map[\"Customer address\"]],\n",
        "        }\n",
        "\n",
        "        # Insert the customer and retrieve their ID\n",
        "        customer_id = insert_customer(customer)\n",
        "\n",
        "        # Skip if customer insertion fails\n",
        "        if not customer_id:\n",
        "            continue\n",
        "\n",
        "\n",
        "        # Prepare order details\n",
        "        order = {\n",
        "            \"order_id\": str(uuid.uuid4()),  # Generate a unique ID for the order\n",
        "            \"customer_id\": customer_id,\n",
        "            \"order_date\": row[column_map[\"Sale date\"]].isoformat()\n",
        "            if isinstance(row[column_map[\"Sale date\"]], pd.Timestamp)\n",
        "            else str(row[column_map[\"Sale date\"]]),\n",
        "            \"order_items\": row[\"order_items\"],\n",
        "            \"order_items_text\": row[\"order_items_text\"],\n",
        "            \"total_amount\": sum(item[\"amount\"] for item in row[\"order_items\"]),\n",
        "            \"order_type\": row[column_map[\"Ordertype name\"]],\n",
        "        }\n",
        "\n",
        "\n",
        "        # Insert the order\n",
        "        insert_order(order)\n",
        "\n",
        "    print(\"Data successfully inserted into Supabase.\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Provide the path to your Excel file\n",
        "    excel_file_path = \"/content/Sales_deta_by_receipt_this_year.xls\"  # Replace with your file path\n",
        "    process_excel(excel_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "J1cggsb4Iu9R",
        "outputId": "97e7afcb-09fd-41e0-ab5f-d0660c038f13"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-58295455a370>:74: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  grouped = data.groupby(\"Receipt no\").apply(lambda group: {\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "APIError",
          "evalue": "{'code': '22P02', 'details': None, 'hint': None, 'message': 'invalid input value for enum order_type: \"Eat in\"'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-58295455a370>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# Provide the path to your Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mexcel_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/Sales_deta_by_receipt_this_year.xls\"\u001b[0m  \u001b[0;31m# Replace with your file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mprocess_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-58295455a370>\u001b[0m in \u001b[0;36mprocess_excel\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Insert the order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0minsert_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data successfully inserted into Supabase.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-58295455a370>\u001b[0m in \u001b[0;36minsert_order\u001b[0;34m(order)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Function to insert orders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minsert_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0msupabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Orders\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Read and process the Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/postgrest/_sync/request_builder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_ReturnT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_request_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIError\u001b[0m: {'code': '22P02', 'details': None, 'hint': None, 'message': 'invalid input value for enum order_type: \"Eat in\"'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import uuid\n",
        "from supabase import create_client, Client\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "\n",
        "if not SUPABASE_URL or not SUPABASE_KEY:\n",
        "    raise ValueError(\"Supabase credentials are missing. Check your .env file.\")\n",
        "\n",
        "# Initialize Supabase client\n",
        "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "# Function to insert unique customers\n",
        "def insert_customer(customer):\n",
        "    existing_customer = supabase.table(\"Customers\").select(\"*\").eq(\"phone_number\", customer[\"phone_number\"]).execute()\n",
        "    if not existing_customer.data:\n",
        "        customer_id = str(uuid.uuid4())  # Generate a unique ID for the customer\n",
        "        customer[\"customer_id\"] = customer_id\n",
        "\n",
        "        # Ensure all values in the customer dictionary are valid JSON types\n",
        "        for key, value in customer.items():\n",
        "            if pd.isnull(value):  # Check for NaN values\n",
        "                customer[key] = None  # Replace NaN with None\n",
        "            elif isinstance(value, float) and (pd.isna(value) or value == float('inf') or value == float('-inf')):\n",
        "                customer[key] = None  # Replace infinite or NaN floats with None\n",
        "\n",
        "        supabase.table(\"Customers\").insert(customer).execute()\n",
        "        return customer_id\n",
        "    return existing_customer.data[0][\"customer_id\"]\n",
        "\n",
        "# Function to insert unique orders\n",
        "def insert_order(order):\n",
        "    # Check for existing order using receipt_id\n",
        "    supabase.table(\"Orders\").insert(order).execute()\n",
        "    # existing_order = supabase.table(\"Orders\").select(\"*\").eq(\"receipt_id\", order[\"receipt_id\"]).execute()\n",
        "    # if not existing_order.data:\n",
        "    #     supabase.table(\"Orders\").insert(order).execute()\n",
        "\n",
        "def process_excel(file_path):\n",
        "    # Read the Excel file\n",
        "    data = pd.read_excel(file_path)\n",
        "\n",
        "    column_map = {\n",
        "        \"Customer name\": \"Customer name\",\n",
        "        \"Customer mobile\": \"Customer mobile\",\n",
        "        \"Customer email\": \"Customer email\",\n",
        "        \"Customer address\": \"Customer address\",\n",
        "        \"Sale date\": \"Sale date\",\n",
        "        \"Receipt no\": \"Receipt no\",  # Used for grouping but not stored in Supabase\n",
        "        \"Ordertype name\": \"Ordertype name\",\n",
        "        \"Item name\": \"Item name\",\n",
        "        \"Variant name\": \"Variant name\",\n",
        "        \"Selling price\": \"Selling price\",\n",
        "        \"Item quantity\": \"Item quantity\",\n",
        "        \"Item amount\": \"Item amount\",\n",
        "    }\n",
        "\n",
        "    # Ensure the necessary columns exist\n",
        "    required_columns = column_map.keys()\n",
        "    for col in required_columns:\n",
        "        if col not in data.columns:\n",
        "            raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "    # Convert numeric columns to proper types\n",
        "    data[\"Item quantity\"] = pd.to_numeric(data[\"Item quantity\"], errors=\"coerce\")\n",
        "    data[\"Item amount\"] = pd.to_numeric(data[\"Item amount\"], errors=\"coerce\")\n",
        "\n",
        "    # Group items by receipt number (used only for grouping here)\n",
        "    grouped = data.groupby(\"Receipt no\").apply(lambda group: {\n",
        "        \"order_items\": group.apply(lambda row: {\n",
        "            \"item_name\": row[\"Item name\"],\n",
        "            \"quantity\": row[\"Item quantity\"],\n",
        "            \"amount\": row[\"Item amount\"],\n",
        "        }, axis=1).tolist(),\n",
        "        \"order_items_text\": \"; \".join(\n",
        "            f'{row[\"Item name\"]} (x{row[\"Item quantity\"]})' for _, row in group.iterrows()\n",
        "        ),\n",
        "    }).reset_index(name=\"grouped_data\")\n",
        "\n",
        "    # Extract grouped data into a DataFrame\n",
        "    grouped_data = pd.json_normalize(grouped[\"grouped_data\"])\n",
        "    grouped = pd.concat([grouped, grouped_data], axis=1)\n",
        "\n",
        "    # Merge grouped data back with the original dataset\n",
        "    final_data = pd.merge(data.drop_duplicates(\"Receipt no\"), grouped, on=\"Receipt no\", how=\"left\")\n",
        "\n",
        "    # Define a mapping for valid order types\n",
        "    order_type_map = {\n",
        "        \"Dine-In\": \"Dine-In\",\n",
        "        \"Delivery\": \"Delivery\",\n",
        "        \"Takeaway\": \"Take away\",  # Map \"Takeaway\" to \"Take away\"\n",
        "        \"Take away\": \"Take away\",  # Allow direct match\n",
        "        \"Eat in\": \"Dine-In\",       # Handle alternate naming\n",
        "    }\n",
        "\n",
        "    # Process customers and orders\n",
        "    for _, row in final_data.iterrows():\n",
        "        # Extract customer details\n",
        "        customer = {\n",
        "            \"name\": row[column_map[\"Customer name\"]],\n",
        "            \"phone_number\": row[column_map[\"Customer mobile\"]],\n",
        "            \"email\": row[column_map[\"Customer email\"]],\n",
        "            \"address\": row[column_map[\"Customer address\"]],\n",
        "        }\n",
        "\n",
        "        # Insert the customer and retrieve their ID\n",
        "        customer_id = insert_customer(customer)\n",
        "\n",
        "        # Skip if customer insertion fails\n",
        "        if not customer_id:\n",
        "            continue\n",
        "\n",
        "        # Get and validate the order type\n",
        "        order_type = row[column_map[\"Ordertype name\"]]\n",
        "        if order_type not in order_type_map:\n",
        "            print(f\"Skipping order with invalid order type: {order_type}\")\n",
        "            continue\n",
        "\n",
        "        # Prepare order details\n",
        "        order = {\n",
        "            \"order_id\": str(uuid.uuid4()),  # Generate a unique ID for the order\n",
        "            \"customer_id\": customer_id,\n",
        "            \"order_date\": row[column_map[\"Sale date\"]].isoformat()\n",
        "            if isinstance(row[column_map[\"Sale date\"]], pd.Timestamp)\n",
        "            else str(row[column_map[\"Sale date\"]]),\n",
        "            \"order_items\": row[\"order_items\"],\n",
        "            \"order_items_text\": row[\"order_items_text\"],\n",
        "            \"total_amount\": sum(item[\"amount\"] for item in row[\"order_items\"]),\n",
        "            \"order_type\": order_type_map[order_type],  # Map to a valid enum type\n",
        "        }\n",
        "\n",
        "        # Insert the order\n",
        "        try:\n",
        "            insert_order(order)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to insert order: {e}\")\n",
        "\n",
        "    print(\"Data successfully inserted into Supabase.\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Provide the path to your Excel file\n",
        "    excel_file_path = \"/content/Sales_deta_by_receipt_last_year.xls\"  # Replace with your file path\n",
        "    process_excel(excel_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "amUcAQlvZPo5",
        "outputId": "6cd39697-7fe3-4b64-8763-87fc394a2c7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4f0120778178>:76: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  grouped = data.groupby(\"Receipt no\").apply(lambda group: {\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "APIError",
          "evalue": "{'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"Customers\"'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4f0120778178>\u001b[0m in \u001b[0;36m<cell line: 149>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Provide the path to your Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mexcel_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/Sales_deta_by_receipt_last_year.xls\"\u001b[0m  \u001b[0;31m# Replace with your file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mprocess_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-4f0120778178>\u001b[0m in \u001b[0;36mprocess_excel\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Insert the customer and retrieve their ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mcustomer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_customer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# Skip if customer insertion fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-4f0120778178>\u001b[0m in \u001b[0;36minsert_customer\u001b[0;34m(customer)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Replace infinite or NaN floats with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0msupabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Customers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcustomer_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexisting_customer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"customer_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/postgrest/_sync/request_builder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_ReturnT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_request_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIError\u001b[0m: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"Customers\"'}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reservation data\n"
      ],
      "metadata": {
        "id": "uqi3H19iEc_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from supabase import create_client, Client\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "# Supabase configuration\n",
        "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "# Load the reservation data\n",
        "# reservation_file = \"Reservation_Details.xlsx\"\n",
        "# df = pd.read_excel(reservation_file)\n",
        "df = pd.read_excel(\"/content/Reservation list update (1).xlsx\", sheet_name=\"Update reservation Sheet\")\n",
        "\n",
        "# Clean up and normalize the data\n",
        "df.columns = df.columns.str.strip()  # Remove extra spaces from column names\n",
        "df[\"Total Bill\"] = pd.to_numeric(df[\"Total Bill\"].str.replace(\",\", \"\").str.replace(\" BDT\", \"\"), errors='coerce')  # Clean bill values\n",
        "df[\"Company Name\"] = df[\"Company Name\"].fillna(\"\")\n",
        "df[\"Mobile Number\"] = df[\"Mobile Number\"].astype(str)\n",
        "\n",
        "# Process each reservation row\n",
        "for _, row in df.iterrows():\n",
        "    phone_number = row[\"Mobile Number\"]\n",
        "    is_returning = row[\"Return Guest\"] == \"Yes\"\n",
        "    is_vip = row[\"Total Bill\"] > 30000 # and (\"family\" not in row[\"Company Name\"].lower() and \"friends\" not in row[\"Company Name\"].lower())\n",
        "    company_name = row[\"Company Name\"] if (\"family\" not in row[\"Company Name\"].lower() and \"friend\" not in row[\"Company Name\"].lower()) else None\n",
        "\n",
        "    # Lookup customer by phone number in Supabase\n",
        "    response = supabase.table(\"Customers\").select(\"*\").eq(\"phone_number\", phone_number).execute()\n",
        "\n",
        "    if response.data:\n",
        "        # Update existing customer\n",
        "        customer_id = response.data[0][\"customer_id\"]\n",
        "        update_data = {\n",
        "            \"is_returning_customer\": is_returning,\n",
        "            \"is_VIP\": is_vip\n",
        "        }\n",
        "        # Update company name if applicable\n",
        "        if company_name:\n",
        "            update_data[\"company_name\"] = company_name\n",
        "\n",
        "        supabase.table(\"Customers\").update(update_data).eq(\"customer_id\", customer_id).execute()\n",
        "    else:\n",
        "        # Optionally create a new customer if the phone number doesn't exist\n",
        "        print(f\"Customer with phone number {phone_number} not found in Supabase.\")\n",
        "        # Uncomment to add the customer\n",
        "        supabase.table(\"Customers\").insert({\n",
        "            \"phone_number\": phone_number,\n",
        "            \"name\": row[\"Guest Name\"],\n",
        "            \"company_name\": company_name if company_name else \"\",\n",
        "            \"is_returning_customer\": is_returning,\n",
        "            \"is_VIP\": is_vip\n",
        "        }).execute()\n",
        "\n",
        "print(\"Update process completed!\")\n"
      ],
      "metadata": {
        "id": "48ueFOHZy01c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "1cb46b3b-4b19-4bb0-a770-1a348afaa926"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer with phone number nan not found in Supabase.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "APIError",
          "evalue": "{'code': 'PGRST102', 'details': None, 'hint': None, 'message': 'Empty or invalid json'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ba9693a1d9a9>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;34m\"is_returning_customer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mis_returning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"is_VIP\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mis_vip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         }).execute()\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Update process completed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/postgrest/_sync/request_builder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_ReturnT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_request_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIError\u001b[0m: {'code': 'PGRST102', 'details': None, 'hint': None, 'message': 'Empty or invalid json'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vchHrQITy0yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDvFw9Apy0vT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}